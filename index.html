<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Vynix AI Training Dashboard</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://www.gstatic.com/firebasejs/10.14.1/firebase-app.js"></script>
  <script src="https://www.gstatic.com/firebasejs/10.14.1/firebase-auth.js"></script>
  <script src="https://www.gstatic.com/firebasejs/10.14.1/firebase-database.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700;800&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700;900&display=swap" rel="stylesheet">
  <style>
    :root {
      --bg: #f8f8f8;
      --card-bg: #ffffff;
      --text-primary: #000000;
      --text-secondary: #666666;
      --border: #e0e0e0;
      --accent: #d40000;
      --bbm-red: #d40000;
      --shadow-sm: 0 2px 4px rgba(0, 0, 0, 0.1);
      --shadow-md: 0 4px 12px rgba(0, 0, 0, 0.1);
      --glow: 0 0 10px rgba(212, 0, 0, 0.3);
    }
    body {
      font-family: 'Inter', sans-serif;
      background: var(--bg);
      color: var(--text-primary);
      margin: 0;
      padding: 0;
      line-height: 1.6;
    }
    .header {
      background: var(--card-bg);
      padding: 20px;
      text-align: center;
      box-shadow: var(--shadow-sm);
      border-bottom: 1px solid var(--border);
    }
    .header h1 {
      font-family: 'Orbitron', monospace;
      color: var(--bbm-red);
      font-weight: 900;
      font-size: 28px;
      letter-spacing: 0.5px;
      text-shadow: 0 0 10px rgba(212, 0, 0, 0.3);
      margin: 0;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
    }
    .add-form, .bulk-form {
      background: var(--card-bg);
      padding: 20px;
      border-radius: 12px;
      box-shadow: var(--shadow-sm);
      margin-bottom: 20px;
      display: flex;
      gap: 12px;
      flex-wrap: wrap;
      align-items: end;
    }
    .add-form input {
      flex: 1;
      min-width: 200px;
      padding: 12px;
      border: 1px solid var(--border);
      border-radius: 6px;
      font-size: 16px;
    }
    .bulk-form {
      flex-direction: column;
      gap: 12px;
      align-items: stretch;
    }
    .bulk-form input[type="file"] {
      padding: 12px;
      border: 1px solid var(--border);
      border-radius: 6px;
      background: white;
    }
    .bulk-form textarea {
      flex: 1;
      min-height: 100px;
      padding: 12px;
      border: 1px solid var(--border);
      border-radius: 6px;
      font-size: 14px;
      resize: vertical;
      font-family: monospace;
    }
    .bulk-preview {
      background: #f0f0f0;
      padding: 12px;
      border-radius: 6px;
      max-height: 200px;
      overflow-y: auto;
      font-size: 12px;
      font-family: monospace;
      white-space: pre-wrap;
    }
    .btn {
      background: var(--bbm-red);
      color: white;
      border: none;
      padding: 12px 20px;
      border-radius: 6px;
      cursor: pointer;
      font-weight: 600;
      transition: all 0.3s ease;
    }
    .btn:hover {
      background: #b30000;
      box-shadow: var(--glow);
    }
    .btn-danger {
      background: #ff4444;
    }
    .btn-danger:hover {
      background: #cc0000;
    }
    .btn-secondary {
      background: #6b7280;
    }
    .btn-secondary:hover {
      background: #4b5563;
    }
    .training-pair {
      background: var(--card-bg);
      padding: 16px;
      border-radius: 12px;
      box-shadow: var(--shadow-sm);
      margin-bottom: 12px;
      display: flex;
      gap: 12px;
      align-items: center;
      flex-wrap: wrap;
    }
    .training-pair input {
      flex: 1;
      min-width: 150px;
      padding: 8px;
      border: 1px solid var(--border);
      border-radius: 4px;
    }
    .pair-actions {
      display: flex;
      gap: 8px;
    }
    .stats {
      text-align: center;
      margin-bottom: 20px;
      font-size: 18px;
      color: var(--text-secondary);
    }
    .loading {
      text-align: center;
      padding: 40px;
      font-style: italic;
      color: var(--text-secondary);
    }
    .error {
      background: #fee;
      color: #c33;
      padding: 12px;
      border-radius: 6px;
      margin: 20px 0;
      border-left: 4px solid #c33;
    }
    .success {
      background: #efe;
      color: #080;
      padding: 12px;
      border-radius: 6px;
      margin: 20px 0;
      border-left: 4px solid #080;
    }
    .hidden {
      display: none !important;
    }
    .progress-bar {
      width: 100%;
      height: 8px;
      background: var(--border);
      border-radius: 4px;
      overflow: hidden;
      margin: 10px 0;
    }
    .progress-fill {
      height: 100%;
      background: var(--bbm-red);
      transition: width 0.3s ease;
      width: 0%;
    }
    .train-section {
      background: var(--card-bg);
      padding: 20px;
      border-radius: 12px;
      box-shadow: var(--shadow-sm);
      margin: 20px 0;
      text-align: center;
    }
    .train-status, .model-status {
      background: var(--card-bg);
      padding: 20px;
      border-radius: 12px;
      box-shadow: var(--shadow-sm);
      margin-bottom: 20px;
      max-height: 300px;
      overflow-y: auto;
    }
    .model-options {
      display: flex;
      flex-direction: column;
      gap: 12px;
      margin-bottom: 16px;
      align-items: center;
    }
    .model-options label {
      display: flex;
      align-items: center;
      gap: 8px;
      font-size: 15px;
    }
    .slider-container {
      display: flex;
      align-items: center;
      gap: 10px;
      font-size: 14px;
      color: var(--text-secondary);
    }
    .slider-container input[type="range"] {
      flex: 1;
    }
    /* Overlay Spinner Styles */
    .overlay-spinner {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: rgba(248, 248, 248, 0.9);
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      z-index: 1000;
      transition: opacity 0.3s ease;
    }
    .overlay-spinner.hidden {
      opacity: 0;
      pointer-events: none;
    }
    .spinner {
      border: 4px solid var(--border);
      border-top: 4px solid var(--bbm-red);
      border-radius: 50%;
      width: 50px;
      height: 50px;
      animation: spin 1s linear infinite;
    }
    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }
    .spinner-text {
      margin-top: 20px;
      font-family: 'Orbitron', monospace;
      color: var(--bbm-red);
      font-weight: 700;
      font-size: 16px;
      letter-spacing: 0.5px;
    }
  </style>
</head>
<body>
  <!-- Overlay Spinner -->
  <div id="overlay-spinner" class="overlay-spinner">
    <div class="spinner"></div>
    <div class="spinner-text" id="spinner-text">Initializing Vynix Dashboard...</div>
  </div>

  <header class="header">
    <h1>Vynix AI Training Dashboard</h1>
    <p>Manage training data for your AI companion</p>
  </header>

  <div class="container">
    <div id="auth-status" class="stats">Loading...</div>
    <div id="stats" class="stats hidden">Total pairs: <span id="pair-count">0</span></div>

    <div id="error-message" class="error hidden"></div>
    <div id="success-message" class="success hidden"></div>

    <form id="add-form" class="add-form hidden">
      <input type="text" id="new-q" placeholder="Question (e.g., 'hello')" required>
      <input type="text" id="new-a" placeholder="Answer (e.g., 'Hi! What's up?')" required>
      <button type="submit" class="btn">Add Pair</button>
    </form>

    <form id="bulk-form" class="bulk-form hidden">
      <div>
        <label for="bulk-input" class="block text-sm font-medium text-gray-700 mb-2">Bulk Upload Options</label>
        <div class="flex gap-4 mb-4">
          <label class="flex items-center">
            <input type="radio" name="bulk-mode" value="csv" checked class="mr-2">
            CSV File (q,a per line)
          </label>
          <label class="flex items-center">
            <input type="radio" name="bulk-mode" value="text" class="mr-2">
            Text (q|a per line)
          </label>
        </div>
      </div>
      <input type="file" id="bulk-input" accept=".csv,.txt" placeholder="Upload CSV or TXT file">
      <textarea id="bulk-text" placeholder="Or paste bulk data here (one pair per line: question|answer)" style="display: none;"></textarea>
      <div id="bulk-preview" class="bulk-preview hidden">Preview will appear here...</div>
      <div class="progress-bar hidden">
        <div id="progress-fill" class="progress-fill"></div>
      </div>
      <button type="submit" class="btn" id="bulk-submit" disabled>Bulk Add Pairs</button>
    </form>

    <div id="loading" class="loading hidden">Loading training data...</div>
    <div id="pairs-list"></div>

    <button id="retrain-btn" class="btn hidden" style="display: block; margin: 20px auto;">Trigger Retrain (Saves & Notifies)</button>

    <!-- Dynamic Train Section -->
    <div id="train-section" class="hidden"></div>
    <div id="train-status" class="train-status hidden"></div>
    <div id="model-status" class="model-status hidden"></div>
  </div>

  <script type="module">
    import { initializeApp } from "https://www.gstatic.com/firebasejs/10.14.1/firebase-app.js";
    import { getAuth, onAuthStateChanged, signInAnonymously, signOut } from "https://www.gstatic.com/firebasejs/10.14.1/firebase-auth.js";
    import { getDatabase, ref, set, push, onValue, remove, update, get } from "https://www.gstatic.com/firebasejs/10.14.1/firebase-database.js";

    const firebaseConfig = {
      apiKey: "AIzaSyBOyZ3As4GTuNvjemvPF_SpsC6m6vqtNhc",
      authDomain: "fire-b-a8878.firebaseapp.com",
      databaseURL: "https://fire-b-a8878.firebaseio.com",
      projectId: "fire-b-a8878",
      storageBucket: "fire-b-a8878.firebasestorage.app",
      messagingSenderId: "658673187627",
      appId: "1:658673187627:web:6e4c29af661785f0afa36e",
      measurementId: "G-V4W97VMSKL"
    };

    const app = initializeApp(firebaseConfig);
    const auth = getAuth(app);
    const db = getDatabase(app);

    const container = document.querySelector('.container');
    const elements = {
      overlaySpinner: document.getElementById('overlay-spinner'),
      spinnerText: document.getElementById('spinner-text'),
      authStatus: document.getElementById('auth-status'),
      stats: document.getElementById('stats'),
      pairCount: document.getElementById('pair-count'),
      errorMessage: document.getElementById('error-message'),
      successMessage: document.getElementById('success-message'),
      addForm: document.getElementById('add-form'),
      newQ: document.getElementById('new-q'),
      newA: document.getElementById('new-a'),
      bulkForm: document.getElementById('bulk-form'),
      bulkInput: document.getElementById('bulk-input'),
      bulkText: document.getElementById('bulk-text'),
      bulkPreview: document.getElementById('bulk-preview'),
      bulkSubmit: document.getElementById('bulk-submit'),
      progressFill: document.getElementById('progress-fill'),
      loading: document.getElementById('loading'),
      pairsList: document.getElementById('pairs-list'),
      retrainBtn: document.getElementById('retrain-btn'),
      trainSection: document.getElementById('train-section'),
      trainStatus: document.getElementById('train-status'),
      modelStatus: document.getElementById('model-status')
    };

    let currentUser;
    let trainingData = {};
    let dataKeys = [];
    let dataLoaded = false;

    // VOCAB SETTINGS
    let MAX_VOCAB = 500;  // Default smaller for generation efficiency
    let MAX_SEQ_LEN = 25;  // Default for seq2seq
    const STOPWORDS = new Set(['the','a','an','and','or','but','in','on','at','to','for','of','with','is','are','was','were','i','you','he','she','it','we','they','this','that','what','how','why','when','where','my','your','his','her','its','our','their','me','him','us','them','be','have','do','does','did','will','would','can','could','should','may','might','must']);

    // Overlay functions
    function showOverlay(text = 'Loading...') {
      elements.spinnerText.textContent = text;
      elements.overlaySpinner.classList.remove('hidden');
    }

    function hideOverlay() {
      elements.overlaySpinner.classList.add('hidden');
    }

    function showError(msg) {
      elements.errorMessage.textContent = msg;
      elements.errorMessage.classList.remove('hidden');
      elements.successMessage.classList.add('hidden');
    }

    function showSuccess(msg) {
      elements.successMessage.textContent = msg;
      elements.successMessage.classList.remove('hidden');
      elements.errorMessage.classList.add('hidden');
    }

    function hideMessages() {
      elements.errorMessage.classList.add('hidden');
      elements.successMessage.classList.add('hidden');
    }

    function updateStats() {
      elements.pairCount.textContent = Object.keys(trainingData).length;
      elements.stats.classList.remove('hidden');
    }

    function renderPairs() {
      elements.pairsList.innerHTML = '';
      dataKeys.forEach(key => {
        const pair = trainingData[key];
        if (!pair || !pair.q || !pair.a) return;

        const pairDiv = document.createElement('div');
        pairDiv.className = 'training-pair';
        pairDiv.innerHTML = `
          <input type="text" value="${pair.q}" data-key="${key}" data-field="q" placeholder="Question">
          <input type="text" value="${pair.a}" data-key="${key}" data-field="a" placeholder="Answer">
          <div class="pair-actions">
            <button class="btn btn-secondary" onclick="updatePair('${key}', this)">Update</button>
            <button class="btn btn-danger" onclick="deletePair('${key}', this)">Delete</button>
          </div>
        `;
        elements.pairsList.appendChild(pairDiv);
      });
      updateStats();
    }

    async function addPair(q, a) {
      if (!currentUser || !q.trim() || !a.trim()) {
        throw new Error('Please log in and enter both question and answer.');
      }
      // Data validation for coherence
      if (q.split(/\s+/).length < 2 || a.split(/\s+/).length < 3 || q.trim().toLowerCase() === a.trim().toLowerCase()) {
        throw new Error('Pairs must be natural: Q at least 2 words, A 3+ words, not identical.');
      }
      const trainingRef = ref(db, 'training_data');
      const newPairRef = push(trainingRef);
      const newPair = { q: q.trim().toLowerCase(), a: a.trim(), timestamp: Date.now() };
      await set(newPairRef, newPair);
      return newPair;
    }

    window.updatePair = async function(key, btn) {
      if (!currentUser) return;
      const inputs = document.querySelectorAll(`[data-key="${key}"]`);
      const qInput = inputs[0].value.trim().toLowerCase();
      const aInput = inputs[1].value.trim();
      if (!qInput || !aInput) {
        showError('Question and answer cannot be empty.');
        return;
      }
      // Re-validate
      if (qInput.split(/\s+/).length < 2 || aInput.split(/\s+/).length < 3 || qInput === aInput) {
        showError('Updated pair must meet natural language rules.');
        return;
      }
      try {
        hideMessages();
        btn.textContent = 'Updating...';
        const pairRef = ref(db, `training_data/${key}`);
        await update(pairRef, { q: qInput, a: aInput, timestamp: Date.now() });
        showSuccess('Pair updated successfully!');
        btn.textContent = 'Update';
      } catch (error) {
        showError('Failed to update pair: ' + error.message);
        btn.textContent = 'Update';
      }
    };

    window.deletePair = async function(key, btn) {
      if (!currentUser) return;
      if (!confirm('Delete this training pair?')) return;
      try {
        hideMessages();
        btn.textContent = 'Deleting...';
        const pairRef = ref(db, `training_data/${key}`);
        await remove(pairRef);
        showSuccess('Pair deleted successfully!');
        btn.textContent = 'Delete';
      } catch (error) {
        showError('Failed to delete pair: ' + error.message);
        btn.textContent = 'Delete';
      }
    };

    async function triggerRetrain() {
      showSuccess('Training data saved! Vynix will retrain automatically in connected apps.');
    }

    // TF.js Helpers
    function textToVector(text, vocab) {
      const vec = new Array(vocab.length).fill(0);
      const words = text.toLowerCase().split(/\s+/).filter(w => w.length > 1);
      words.forEach(word => {
        const idx = vocab.indexOf(word);
        if (idx > -1) vec[idx] = 1;
      });
      return vec;
    }

    function questionToSequence(text, wordToIdx, maxLen) {
      const words = text.toLowerCase().split(/\s+/).filter(w => w.length > 1);
      let seq = words.map(w => wordToIdx.get(w) || 1);
      seq = seq.concat(Array(maxLen - seq.length).fill(0));
      return seq.slice(0, maxLen);
    }

    function buildVocab(pairs) {
      const wordCount = {};
      pairs.forEach(pair => {
        [pair.q, pair.a].forEach(text => {
          text.toLowerCase().split(/\s+/).forEach(word => {
            if (word.length > 2 && !STOPWORDS.has(word)) {
              wordCount[word] = (wordCount[word] || 0) + 1;
            }
          });
        });
      });

      return Object.keys(wordCount)
        .filter(w => wordCount[w] >= 1)  // Lower for generation
        .sort()
        .slice(0, MAX_VOCAB);
    }

    function encodeAnswers(pairs, uniqueAnswers) {
      const answerToIdx = {};
      uniqueAnswers.forEach((ans, idx) => { answerToIdx[ans] = idx; });
      return pairs.map(pair => answerToIdx[pair.a]);
    }

    function smoothedOneHot(indices, vocabSize, epsilon = 0.1) {
      const oneHots = tf.oneHot(tf.tensor1d(indices, 'int32'), vocabSize);
      const noise = tf.fill([indices.length, vocabSize], epsilon / (vocabSize - 1));
      const smoothed = oneHots.mul(1 - epsilon).add(noise.mul(oneHots.notEqual(1).toFloat()));
      oneHots.dispose();
      noise.dispose();
      return smoothed;
    }

    function pairToSequences(qText, aText, wordToIdx, maxLen) {
      const qWords = qText.toLowerCase().split(/\s+/).filter(w => w.length > 1);
      const aWords = aText.toLowerCase().split(/\s+/).filter(w => w.length > 1);
      
      // Encoder input: Question sequence
      let qSeq = qWords.map(w => wordToIdx.get(w) || 1).concat(Array(maxLen - qWords.length).fill(0));
      qSeq = qSeq.slice(0, maxLen);
      
      // Decoder input: Answer shifted (teacher forcing)
      let decoderInput = [wordToIdx.get('<START>') || 2];  // Start token
      decoderInput = decoderInput.concat(aWords.slice(0, -1).map(w => wordToIdx.get(w) || 1));  // All but last
      decoderInput = decoderInput.concat(Array(maxLen - decoderInput.length).fill(0));
      decoderInput = decoderInput.slice(0, maxLen);
      
      // Decoder target: Answer sequence
      let decoderTargetWords = aWords.map(w => wordToIdx.get(w) || 1);
      const targetSeq = decoderTargetWords.concat(Array(maxLen - decoderTargetWords.length).fill(0));
      const targetOneHot = smoothedOneHot(targetSeq, wordToIdx.size, 0.1);  // Smoothed
      
      return { qSeq, decoderInput, targetOneHot };
    }

    async function generateResponse(model, encoder, decoder, inputSeq, wordToIdx, idxToWord, maxLen, temperature = 0.7, topP = 0.9, repetitionPenalty = 1.1) {
      let inputCopy = tf.tensor2d([inputSeq]);
      let states = await encoder.predict(inputCopy);
      inputCopy.dispose();

      let outputSeq = [2];  // <START> index
      let generated = [];
      const recentWords = new Set();

      for (let i = 0; i < maxLen; i++) {
        let decInput = tf.tensor2d([outputSeq.slice(-10)]);  // Last 10 for context
        while (decInput.shape[1] < maxLen) {
          decInput = tf.pad(decInput, [[0,0], [0, maxLen - decInput.shape[1]]], 'CONSTANT', 0);
        }

        let [nextWordProbs, nextStates] = await decoder.predict([decInput, states]);
        decInput.dispose();

        let probsData = nextWordProbs.dataSync()[0];
        
        // Repetition penalty
        for (let j = 0; j < probsData.length; j++) {
          const word = idxToWord.get(j);
          if (recentWords.has(word) && word !== '<END>') {
            probsData[j] /= repetitionPenalty;
          }
        }
        
        // Normalize
        const sum = probsData.reduce((a, b) => a + b, 0);
        probsData = probsData.map(p => p / sum);

        // Top-p sampling
        const sortedProbs = [...probsData].sort((a, b) => b - a);
        const sortedIdx = probsData.map((_, i) => i).sort((a, b) => probsData[b] - probsData[a]);
        let cumProb = 0;
        let cutoff = 0;
        for (let j = 0; j < sortedProbs.length; j++) {
          cumProb += sortedProbs[j];
          if (cumProb > topP) {
            cutoff = j + 1;
            break;
          }
        }
        const candidates = sortedIdx.slice(0, cutoff);
        const candidateProbs = candidates.map(idx => probsData[idx] ** (1 / temperature));
        const candSum = candidateProbs.reduce((a, b) => a + b, 0);
        const rand = Math.random() * candSum;
        let cumulative = 0;
        let nextIdx = candidates[0];
        for (let j = 0; j < candidateProbs.length; j++) {
          cumulative += candidateProbs[j];
          if (rand <= cumulative) {
            nextIdx = candidates[j];
            break;
          }
        }

        const word = idxToWord.get(nextIdx) || '<UNK>';
        generated.push(word);
        recentWords.add(word);
        if (recentWords.size > 10) recentWords.delete([...recentWords][0]);

        if (word === '<END>' || word === '<UNK>' || generated.length > 15) break;
        outputSeq.push(nextIdx);
        outputSeq = outputSeq.slice(-maxLen);

        states = nextStates;
        nextWordProbs.dispose();
        nextStates.forEach(s => s.dispose());
      }
      return generated.join(' ').replace(/\b(?:the|a|an|and|or|but)\s+/gi, ' ').trim();
    }

    async function loadModelFromSaved(saved) {
      let model;
      if (saved.modelType === 'classifier') {
        model = tf.sequential({
          layers: [
            tf.layers.dense({ inputShape: [saved.inputDim], units: 64, activation: 'relu' }),
            tf.layers.dropout({ rate: 0.2 }),
            tf.layers.dense({ units: saved.numClasses, activation: 'softmax' })
          ]
        });
      } else if (saved.modelType === 'lstm') {
        model = tf.sequential({
          layers: [
            tf.layers.embedding({
              inputDim: saved.vocabSize,
              outputDim: saved.embedDim || 32,
              inputLength: saved.maxLen
            }),
            tf.layers.lstm({
              units: saved.lstmUnits || 64,
              dropout: 0.2
            }),
            tf.layers.dense({ units: saved.numClasses, activation: 'softmax' })
          ]
        });
      } else if (saved.modelType === 'generative') {
        // Rebuild generative model
        const embedLayer = tf.layers.embedding({ inputDim: saved.vocabSize, outputDim: 32, inputLength: saved.maxLen });
        const encoderLSTM = tf.layers.lstm({ units: 64, returnState: true, dropout: 0.2 });
        const decoderLSTM = tf.layers.lstm({ units: 64, returnSequences: true, dropout: 0.2 });
        const dense = tf.layers.dense({ units: saved.vocabSize, activation: 'softmax' });

        const wordToIdx = new Map(saved.wordToIdx);
        const idxToWord = new Map(saved.idxToWord);

        // Simplified weight set (adjust slicing as needed)
        const weights = saved.weights;
        let weightIdx = 0;
        const setLayerWeights = (layer, numWeights) => {
          const layerWeights = weights.slice(weightIdx, weightIdx + numWeights).map(arr => tf.tensor(arr));
          layer.setWeights(layerWeights);
          weightIdx += numWeights;
          layerWeights.forEach(w => w.dispose());
        };
        // Approximate counts: embedding (2), lstm enc (8), lstm dec (8), dense (2)
        setLayerWeights(embedLayer, 2);
        setLayerWeights(encoderLSTM, 8);
        setLayerWeights(decoderLSTM, 8);
        setLayerWeights(dense, 2);

        model = {
          encoder: tf.model({ inputs: tf.input({shape: [saved.maxLen]}), outputs: encoderLSTM.apply(embedLayer.apply(tf.input({shape: [saved.maxLen]}))) }),
          decoder: tf.model({ 
            inputs: [tf.input({shape: [saved.maxLen]}), /* states placeholder */],
            outputs: dense.apply(decoderLSTM.apply(embedLayer.apply(tf.input({shape: [saved.maxLen]})), { initialState: /* states */ }))
          }),  // Note: Full rebuild may need custom predict wrapper
          embedLayer, encoderLSTM, decoderLSTM, dense, wordToIdx, idxToWord, vocabSize: saved.vocabSize, maxLen: saved.maxLen
        };
        model.encoder.compile({ optimizer: 'adam', loss: 'categoricalCrossentropy' });
        model.decoder.compile({ optimizer: 'adam', loss: 'categoricalCrossentropy' });
      }
      model.compile({
        optimizer: 'adam',
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy']
      });

      const weightTensors = saved.weights.map(arr => tf.tensor(arr));
      model.setWeights(weightTensors);
      weightTensors.forEach(t => t.dispose());

      return { model, vocab: saved.vocab, uniqueAnswers: saved.uniqueAnswers || [], modelType: saved.modelType, wordToIdx: saved.wordToIdx, idxToWord: saved.idxToWord };
    }

    async function trainModel() {
      if (Object.keys(trainingData).length < 10) {
        showError('Need at least 10 training pairs for a basic model.');
        return;
      }

      elements.trainStatus.classList.remove('hidden');
      elements.trainStatus.innerHTML = '<p class="loading">Preparing data... (Enable WebGL for faster training)</p>';
      elements.modelStatus.classList.add('hidden');
      const progressBar = elements.progressFill.parentElement;
      progressBar.classList.remove('hidden');

      try {
        await tf.setBackend('webgl');
        await tf.ready();

        const pairs = dataKeys.map(key => ({ q: trainingData[key].q, a: trainingData[key].a }));
        const modelType = document.querySelector('input[name="model-type"]:checked').value;
        const retrain = document.getElementById('retrain-toggle').checked;
        const useSmoothing = document.getElementById('smooth-labels').checked;
        const temperature = parseFloat(document.getElementById('temp-slider').value);
        const topP = parseFloat(document.getElementById('topp-slider').value);
        let model, xs, sampleInput, vocab, vocabSize, maxLen, isLoaded = false, wordToIdx, idxToWord;

        const modelRef = ref(db, 'models/current-model');

        if (retrain) {
          const snap = await get(modelRef);
          if (snap.exists() && snap.val().modelType === modelType) {
            const saved = snap.val();
            isLoaded = true;
            let savedVocab;
            if (modelType === 'classifier') {
              savedVocab = saved.vocab;
              const qs = pairs.map(p => textToVector(p.q, savedVocab));
              xs = tf.tensor2d(qs);
              sampleInput = tf.tensor2d([textToVector('hello how are you today', savedVocab)]);
              vocabSize = savedVocab.length;
            } else if (modelType === 'lstm') {
              savedVocab = saved.vocab;
              wordToIdx = new Map([['<PAD>', 0], ['<UNK>', 1]]);
              savedVocab.forEach((word, i) => wordToIdx.set(word, i + 2));
              maxLen = saved.maxLen;
              const sequences = pairs.map(p => questionToSequence(p.q, wordToIdx, maxLen));
              xs = tf.tensor2d(sequences);
              sampleInput = tf.tensor2d([questionToSequence('hello how are you today', wordToIdx, maxLen)]);
              vocabSize = saved.vocabSize;
            } else if (modelType === 'generative') {
              wordToIdx = new Map(saved.wordToIdx);
              idxToWord = new Map(saved.idxToWord);
              maxLen = saved.maxLen;
              const sequences = pairs.map(p => pairToSequences(p.q, p.a, wordToIdx, maxLen));
              // xs as encoder inputs, etc. (handled in loop)
              sampleInput = questionToSequence('hello how are you today', wordToIdx, maxLen);
              vocabSize = saved.vocabSize;
            }
            const loadedStuff = await loadModelFromSaved(saved);
            model = loadedStuff.model;
            vocab = savedVocab;
            elements.trainStatus.innerHTML += '<p>Loaded existing model for retraining.</p>';
          }
        }

        if (!isLoaded) {
          vocab = buildVocab(pairs);
          vocabSize = modelType === 'generative' ? vocab.length + 4 : vocab.length;

          if (modelType === 'classifier') {
            const qs = pairs.map(p => textToVector(p.q, vocab));
            xs = tf.tensor2d(qs);
            sampleInput = tf.tensor2d([textToVector('hello how are you today', vocab)]);
            model = tf.sequential({
              layers: [
                tf.layers.dense({ inputShape: [vocabSize], units: 64, activation: 'relu' }),
                tf.layers.dropout({ rate: 0.2 }),
                tf.layers.dense({ units: pairs.map(p => p.a).length, activation: 'softmax' })  // Dynamic classes
              ]
            });
          } else if (modelType === 'lstm') {
            wordToIdx = new Map([['<PAD>', 0], ['<UNK>', 1]]);
            vocab.forEach((word, i) => wordToIdx.set(word, i + 2));
            vocabSize = vocab.length + 2;
            maxLen = Math.min(MAX_SEQ_LEN, Math.max(10, ...pairs.map(p => 
              p.q.toLowerCase().split(/\s+/).filter(w => w.length > 1).length
            )));
            const sequences = pairs.map(p => questionToSequence(p.q, wordToIdx, maxLen));
            xs = tf.tensor2d(sequences);
            sampleInput = tf.tensor2d([questionToSequence('hello how are you today', wordToIdx, maxLen)]);
            model = tf.sequential({
              layers: [
                tf.layers.embedding({ inputDim: vocabSize, outputDim: 32, inputLength: maxLen }),
                tf.layers.lstm({ units: 64, dropout: 0.2 }),
                tf.layers.dense({ units: pairs.map(p => p.a).length, activation: 'softmax' })
              ]
            });
          } else if (modelType === 'generative') {
            wordToIdx = new Map([['<PAD>', 0], ['<UNK>', 1], ['<START>', 2], ['<END>', 3]]);
            vocab.forEach((word, i) => wordToIdx.set(word, i + 4));
            idxToWord = new Map([...wordToIdx.entries()].map(([k, v]) => [v, k]));
            vocabSize = vocab.length + 4;
            maxLen = MAX_SEQ_LEN;

            const embedLayer = tf.layers.embedding({ inputDim: vocabSize, outputDim: 32, inputLength: maxLen });
            const encoderLSTM = tf.layers.lstm({ units: 64, returnState: true, dropout: 0.2 });
            const decoderLSTM = tf.layers.lstm({ units: 64, returnSequences: true, dropout: 0.2 });
            const dense = tf.layers.dense({ units: vocabSize, activation: 'softmax' });

            model = {
              encoder: tf.model({ inputs: embedLayer.apply(tf.input({shape: [maxLen]})), outputs: encoderLSTM.apply(embedLayer.apply(tf.input({shape: [maxLen]}))) }),
              decoder: tf.model({ inputs: [embedLayer.apply(tf.input({shape: [maxLen]})), encoderLSTM.outputs], outputs: dense.apply(decoderLSTM.apply(embedLayer.apply(tf.input({shape: [maxLen]})), { initialState: encoderLSTM.outputs })) }),
              embedLayer, encoderLSTM, decoderLSTM, dense, wordToIdx, idxToWord, vocabSize, maxLen
            };

            model.encoder.compile({ optimizer: tf.train.adam(0.001), loss: 'categoricalCrossentropy' });
            model.decoder.compile({ optimizer: tf.train.adam(0.001), loss: 'categoricalCrossentropy' });
          }

          if (modelType !== 'generative') {
            model.compile({
              optimizer: tf.train.adam(0.001),
              loss: 'categoricalCrossentropy',
              metrics: ['accuracy']
            });
          }
        }

        if (modelType !== 'generative') {
          const uniqueAnswers = [...new Set(pairs.map(p => p.a))];
          const answerIndices = encodeAnswers(pairs, uniqueAnswers);
          const ys = tf.oneHot(tf.tensor1d(answerIndices, 'int32'), uniqueAnswers.length);

          const numEpochs = retrain ? 25 : 75;
          const batchSize = Math.min(64, Math.floor(pairs.length / 4));
          let bestValAcc = -Infinity;
          let patienceCounter = 0;
          const patience = 8;

          elements.trainStatus.innerHTML += `<p>Manual training: ${numEpochs} epochs max, batch ${batchSize}</p>`;

          for (let epoch = 0; epoch < numEpochs; epoch++) {
            const shuffled = tf.randomShuffle(tf.stack([xs, ys]));
            const trainXs = shuffled.slice([0, 0], [pairs.length * 0.8, -1]).squeeze();
            const trainYs = shuffled.slice([0, 0, 0], [pairs.length * 0.8, -1, -1]).squeeze();
            const valXs = xs.slice([pairs.length * 0.8, 0], [pairs.length * 0.2, -1]);
            const valYs = ys.slice([pairs.length * 0.8, 0, 0], [pairs.length * 0.2, -1, -1]);

            model.trainOnBatch(trainXs, trainYs);

            const valLogs = model.evaluate(valXs, valYs, { verbose: 0 });
            const valAcc = valLogs[1].dataSync()[0];
            const trainLogs = model.evaluate(trainXs, trainYs, { verbose: 0 });
            const trainAcc = trainLogs[1].dataSync()[0];

            elements.trainStatus.innerHTML += `<p>Epoch ${epoch + 1}: Train Acc=${trainAcc.toFixed(4)}, Val Acc=${valAcc.toFixed(4)}</p>`;

            if (valAcc > bestValAcc) {
              bestValAcc = valAcc;
              patienceCounter = 0;
            } else {
              patienceCounter++;
              if (patienceCounter >= patience) {
                elements.trainStatus.innerHTML += `<p>Early stopping at epoch ${epoch + 1}</p>`;
                break;
              }
            }

            // LR decay every 10 epochs
            if (epoch % 10 === 0 && epoch > 0) {
              const optimizer = model.optimizer;
              optimizer.learningRate = optimizer.learningRate.mul(0.9);
            }

            trainXs.dispose(); trainYs.dispose(); valXs.dispose(); valYs.dispose();
            valLogs.forEach(log => log.dispose());
            trainLogs.forEach(log => log.dispose());

            const progress = ((epoch + 1) / numEpochs) * 100;
            elements.progressFill.style.width = `${progress}%`;
          }

          const pred = model.predict(sampleInput);
          const predIdx = pred.argMax(-1).dataSync()[0];
          const predictedA = uniqueAnswers[predIdx];
          elements.trainStatus.innerHTML += `<p>Test: Predicted "${predictedA}"</p>`;

          pred.dispose();
        } else {
          // Generative training
          const sequences = pairs.map(p => pairToSequences(p.q, p.a, wordToIdx, maxLen));
          const numEpochs = retrain ? 30 : 60;
          let avgLoss = 0;
          let bestPerplexity = Infinity;
          let patienceCounter = 0;
          const patience = 10;

          for (let epoch = 0; epoch < numEpochs; epoch++) {
            let epochLoss = 0;
            for (let i = 0; i < sequences.length; i += 32) {
              const batchEnd = Math.min(i + 32, sequences.length);
              const batchSeqs = sequences.slice(i, batchEnd);
              const batchXsEnc = tf.tensor2d(batchSeqs.map(s => s.qSeq));
              const batchXsDec = tf.tensor2d(batchSeqs.map(s => s.decoderInput));
              const batchYs = tf.stack(batchSeqs.map(s => s.targetOneHot));

              const encStates = model.encoder.predict(batchXsEnc);
              const decOut = model.decoder.predict([batchXsDec, encStates]);
              const lossTensor = model.decoder.evaluate(batchXsDec, batchYs, { verbose: 0 })[0];
              const batchLoss = lossTensor.dataSync()[0];
              epochLoss += batchLoss;

              batchXsEnc.dispose(); batchXsDec.dispose(); batchYs.dispose();
              encStates.forEach(s => s.dispose());
              decOut.forEach(o => o.dispose());
              lossTensor.dispose();
            }
            avgLoss = epochLoss / Math.ceil(sequences.length / 32);
            const avgPerplexity = Math.exp(avgLoss);
            elements.trainStatus.innerHTML += `<p>Epoch ${epoch + 1}: Loss=${avgLoss.toFixed(4)}, Perplexity=${avgPerplexity.toFixed(2)}</p>`;

            if (avgPerplexity < bestPerplexity) {
              bestPerplexity = avgPerplexity;
              patienceCounter = 0;
            } else {
              patienceCounter++;
              if (patienceCounter >= patience || (avgPerplexity < 2.5 && epoch > 30)) {
                elements.trainStatus.innerHTML += `<p>Early stopping at epoch ${epoch + 1} (perplexity ${avgPerplexity.toFixed(2)})</p>`;
                break;
              }
            }

            const progress = ((epoch + 1) / numEpochs) * 100;
            elements.progressFill.style.width = `${progress}%`;

            sequences.forEach(s => s.targetOneHot.dispose());
          }

          const sampleQ = questionToSequence('hello how are you today', wordToIdx, maxLen);
          const generated = await generateResponse(model, model.encoder, model.decoder, sampleQ, wordToIdx, idxToWord, maxLen, temperature, topP, 1.1);
          elements.trainStatus.innerHTML += `<p>Test: Generated "${generated}"</p>`;
        }

        const weights = model.getWeights ? model.getWeights().map(w => w.arraySync()) : [
          ...model.embedLayer.getWeights().map(w => w.arraySync()),
          ...model.encoderLSTM.getWeights().map(w => w.arraySync()),
          ...model.decoderLSTM.getWeights().map(w => w.arraySync()),
          ...model.dense.getWeights().map(w => w.arraySync())
        ];

        const saveData = {
          modelType,
          version: '1.2',  // Updated
          userId: currentUser.uid,
          timestamp: Date.now(),
          vocab,
          uniqueAnswers: modelType !== 'generative' ? [...new Set(pairs.map(p => p.a))] : [],
          numClasses: modelType !== 'generative' ? pairs.map(p => p.a).length : undefined,
          weights,
          temperature, topP, repetitionPenalty: 1.1, epsilon: 0.1
        };
        if (modelType === 'classifier') {
          saveData.inputDim = vocabSize;
        } else if (modelType === 'lstm' || modelType === 'generative') {
          saveData.vocabSize = vocabSize;
          saveData.maxLen = maxLen || MAX_SEQ_LEN;
          saveData.embedDim = 32;
          saveData.lstmUnits = 64;
          if (modelType === 'generative') {
            saveData.wordToIdx = Array.from(wordToIdx.entries());
            saveData.idxToWord = Array.from(idxToWord.entries());
          }
        }
        await set(modelRef, saveData);

        elements.trainStatus.innerHTML += '<p>Model saved! Verification complete.</p>';
        elements.modelStatus.innerHTML = `<p class="success">Model: ${modelType.toUpperCase()} trained & saved! Use in chat UI.</p>`;
        elements.modelStatus.classList.remove('hidden');
        showSuccess('Training completeâ€”model ready for conversational use.');

        // Cleanup
        if (xs) xs.dispose();
        if (sampleInput) sampleInput.dispose();
        if (model && model.dispose) model.dispose();

        progressBar.classList.add('hidden');
        elements.progressFill.style.width = '0%';

      } catch (error) {
        elements.trainStatus.innerHTML += `<p class="error">Training failed: ${error.message}</p>`;
        showError('Training error: ' + error.message);
        console.error('Training error:', error);
        elements.progressFill.parentElement.classList.add('hidden');
      }
    }

    function loadTrainingData() {
      showOverlay('Fetching training data...');
      const trainingRef = ref(db, 'training_data');
      onValue(trainingRef, (snapshot) => {
        const data = snapshot.val();
        trainingData = data || {};
        dataKeys = Object.keys(trainingData);
        renderPairs();
        elements.loading.classList.add('hidden');

        if (!dataLoaded) {
          dataLoaded = true;
          hideOverlay();
        }

        if (elements.trainSection.children.length === 0) {
          elements.trainSection.innerHTML = `
            <section class="train-section">
              <div class="model-options">
                <label>
                  <input type="checkbox" id="retrain-toggle"> Retrain existing model (no delete)
                </label>
                <label>
                  <input type="radio" name="model-type" value="classifier"> Classifier (fast retrieval)
                </label>
                <label>
                  <input type="radio" name="model-type" value="lstm"> LSTM (sequence input)
                </label>
                <label>
                  <input type="radio" name="model-type" value="generative" checked> Generative LSTM (conversational replies)
                </label>
                <label class="flex items-center gap-2">
                  <input type="checkbox" id="smooth-labels" checked> Label Smoothing (reduces overconfidence)
                </label>
                <div class="slider-container">
                  <span>Max Vocab:</span>
                  <input type="range" id="vocab-slider" min="200" max="800" value="500" step="100">
                  <span id="vocab-value">500</span>
                </div>
                <div class="slider-container">
                  <span>Max Seq Len:</span>
                  <input type="range" id="seq-slider" min="10" max="50" value="25" step="5">
                  <span id="seq-value">25</span>
                </div>
                <div class="slider-container">
                  <span>Generation Temp (0.5=safe, 1.0=creative):</span>
                  <input type="range" id="temp-slider" min="0.3" max="1.2" value="0.7" step="0.1">
                  <span id="temp-value">0.7</span>
                </div>
                <div class="slider-container">
                  <span>Top-p (0.8-0.95 for sanity):</span>
                  <input type="range" id="topp-slider" min="0.5" max="1.0" value="0.9" step="0.05">
                  <span id="topp-value">0.9</span>
                </div>
              </div>
              <button id="train-btn" class="btn">Train AI Model</button>
            </section>
          `;

          // Sliders
          const vocabSlider = document.getElementById('vocab-slider');
          const vocabValue = document.getElementById('vocab-value');
          vocabSlider.addEventListener('input', () => {
            MAX_VOCAB = parseInt(vocabSlider.value);
            vocabValue.textContent = MAX_VOCAB;
          });

          const seqSlider = document.getElementById('seq-slider');
          const seqValue = document.getElementById('seq-value');
          seqSlider.addEventListener('input', () => {
            MAX_SEQ_LEN = parseInt(seqSlider.value);
            seqValue.textContent = MAX_SEQ_LEN;
          });

          const tempSlider = document.getElementById('temp-slider');
          const tempValue = document.getElementById('temp-value');
          tempSlider.addEventListener('input', () => tempValue.textContent = tempSlider.value);

          const toppSlider = document.getElementById('topp-slider');
          const toppValue = document.getElementById('topp-value');
          toppSlider.addEventListener('input', () => toppValue.textContent = toppSlider.value);

          document.getElementById('train-btn').addEventListener('click', trainModel);
        }
        elements.trainSection.classList.remove('hidden');
      }, (error) => {
        showError('Failed to load training data: ' + error.message);
        elements.loading.classList.add('hidden');
        if (!dataLoaded) {
          dataLoaded = true;
          hideOverlay();
        }
      });
    }

    // Bulk functionality
    function parseBulkData(content, mode) {
      let lines;
      if (mode === 'csv') {
        lines = content.split('\n').slice(1).filter(line => line.trim());
        let pairs = lines.map(line => {
          const [q, a] = line.split(',').map(s => s.trim().replace(/"/g, ''));
          return { q, a };
        }).filter(pair => pair.q && pair.a);
        // Validate
        return pairs.filter(pair => pair.q.split(/\s+/).length >= 2 && pair.a.split(/\s+/).length >= 3 && pair.q !== pair.a);
      } else {
        lines = content.split('\n').filter(line => line.trim());
        let pairs = lines.map(line => {
          const [q, a] = line.split('|').map(s => s.trim());
          return { q, a };
        }).filter(pair => pair.q && pair.a);
        // Validate
        return pairs.filter(pair => pair.q.split(/\s+/).length >= 2 && pair.a.split(/\s+/).length >= 3 && pair.q !== pair.a);
      }
    }

    function updateBulkPreview(pairs) {
      if (pairs.length === 0) {
        elements.bulkPreview.textContent = 'No valid pairs found (check length/uniqueness).';
        elements.bulkSubmit.disabled = true;
      } else {
        elements.bulkPreview.textContent = `${pairs.length} valid pairs parsed:\n\n${pairs.slice(0, 10).map(p => `${p.q} | ${p.a}`).join('\n')}${pairs.length > 10 ? '\n\n... (showing first 10)' : ''}`;
        elements.bulkSubmit.disabled = false;
      }
      elements.bulkPreview.classList.remove('hidden');
    }

    async function handleBulkSubmit(e) {
      e.preventDefault();
      const mode = document.querySelector('input[name="bulk-mode"]:checked').value;
      let content = '';

      if (mode === 'text') {
        content = elements.bulkText.value;
      } else {
        const file = elements.bulkInput.files[0];
        if (!file) {
          showError('Please select a file.');
          return;
        }
        const text = await file.text();
        content = text;
      }

      const pairs = parseBulkData(content, mode);
      if (pairs.length === 0) {
        showError('No valid pairs found (ensure natural language format).');
        return;
      }

      const progressBar = elements.progressFill.parentElement;
      progressBar.classList.remove('hidden');
      hideMessages();

      let added = 0;
      let errors = 0;
      for (let i = 0; i < pairs.length; i++) {
        try {
          await addPair(pairs[i].q, pairs[i].a);
          added++;
        } catch (error) {
          errors++;
          console.error(`Failed to add pair ${i + 1}:`, error);
        }
        const progress = ((i + 1) / pairs.length) * 100;
        elements.progressFill.style.width = `${progress}%`;
      }

      progressBar.classList.add('hidden');
      elements.progressFill.style.width = '0%';

      if (added > 0) {
        showSuccess(`Bulk upload complete: ${added} pairs added, ${errors} errors.`);
        if (mode === 'text') {
          elements.bulkText.value = '';
        } else {
          elements.bulkInput.value = '';
        }
        elements.bulkPreview.classList.add('hidden');
      } else {
        showError('Bulk upload failed: No pairs added.');
      }
    }

    // Event listeners
    elements.addForm.addEventListener('submit', (e) => {
      e.preventDefault();
      const q = elements.newQ.value;
      const a = elements.newA.value;
      addPair(q, a).then(() => {
        elements.newQ.value = '';
        elements.newA.value = '';
        showSuccess('Pair added successfully!');
      }).catch(error => {
        showError(error.message);
      });
    });

    elements.retrainBtn.addEventListener('click', triggerRetrain);

    elements.bulkForm.addEventListener('submit', handleBulkSubmit);

    const modeRadios = document.querySelectorAll('input[name="bulk-mode"]');
    modeRadios.forEach(radio => {
      radio.addEventListener('change', (e) => {
        const isText = e.target.value === 'text';
        elements.bulkInput.style.display = isText ? 'none' : 'block';
        elements.bulkText.style.display = isText ? 'block' : 'none';
        elements.bulkPreview.classList.add('hidden');
        elements.bulkSubmit.disabled = true;
      });
    });

    elements.bulkInput.addEventListener('change', async (e) => {
      const file = e.target.files[0];
      if (!file) return;
      const content = await file.text();
      const pairs = parseBulkData(content, 'csv');
      updateBulkPreview(pairs);
    });

    elements.bulkText.addEventListener('input', (e) => {
      const content = e.target.value;
      const pairs = parseBulkData(content, 'text');
      updateBulkPreview(pairs);
    });

    onAuthStateChanged(auth, (user) => {
      currentUser = user;
      if (user) {
        showOverlay('Authenticating...');
        elements.authStatus.innerHTML = `Logged in as: ${user.displayName || user.email || 'User'} <button class="btn btn-secondary" onclick="signOutUser()" style="font-size: 12px; padding: 4px 8px; margin-left: 10px;">Sign Out</button>`;
        elements.addForm.classList.remove('hidden');
        elements.bulkForm.classList.remove('hidden');
        elements.retrainBtn.classList.remove('hidden');
        elements.trainSection.classList.remove('hidden');
        loadTrainingData();
      } else {
        hideOverlay();
        elements.authStatus.innerHTML = 'Not logged in. <button class="btn" onclick="signInAnonymously()">Sign In Anonymously</button>';
        elements.addForm.classList.add('hidden');
        elements.bulkForm.classList.add('hidden');
        elements.retrainBtn.classList.add('hidden');
        elements.trainSection.classList.add('hidden');
        elements.pairsList.innerHTML = '<p class="loading">Please sign in to manage training data.</p>';
        elements.loading.classList.add('hidden');
      }
    });

    window.signInAnonymously = async function() {
      try {
        showOverlay('Signing in...');
        await signInAnonymously(auth);
      } catch (error) {
        showError('Sign in failed: ' + error.message);
        hideOverlay();
      }
    };

    window.signOutUser = async function() {
      try {
        await signOut(auth);
      } catch (error) {
        showError('Sign out failed: ' + error.message);
      }
    };

    // Initial load
    showOverlay('Connecting to Firebase...');
    elements.loading.classList.add('hidden');
  </script>
</body>
</html>
